--- a/drivers/net/ethernet/mediatek/mtk_ppe.c
+++ b/drivers/net/ethernet/mediatek/mtk_ppe.c
@@ -329,6 +329,24 @@ int mtk_foe_entry_set_pppoe(struct mtk_f
 	return 0;
 }
 
+int mtk_foe_entry_set_wdma(struct mtk_foe_entry *entry, int wdma_idx, int txq,
+			   int bss, int wcid)
+{
+	struct mtk_foe_mac_info *l2 = mtk_foe_entry_l2(entry);
+	u32 *ib2 = mtk_foe_entry_ib2(entry);
+
+	*ib2 &= ~MTK_FOE_IB2_PORT_MG;
+	*ib2 |= MTK_FOE_IB2_WDMA_WINFO;
+	if (wdma_idx)
+		*ib2 |= MTK_FOE_IB2_WDMA_DEVIDX;
+
+	l2->vlan2 = FIELD_PREP(MTK_FOE_VLAN2_WINFO_BSS, bss) |
+		    FIELD_PREP(MTK_FOE_VLAN2_WINFO_WCID, wcid) |
+		    FIELD_PREP(MTK_FOE_VLAN2_WINFO_RING, txq);
+
+	return 0;
+}
+
 static inline bool mtk_foe_entry_usable(struct mtk_foe_entry *entry)
 {
 	return !(entry->ib1 & MTK_FOE_IB1_STATIC) &&
--- a/drivers/net/ethernet/mediatek/mtk_ppe.h
+++ b/drivers/net/ethernet/mediatek/mtk_ppe.h
@@ -48,9 +48,9 @@ enum {
 #define MTK_FOE_IB2_DEST_PORT		GENMASK(7, 5)
 #define MTK_FOE_IB2_MULTICAST		BIT(8)
 
-#define MTK_FOE_IB2_WHNAT_QID2		GENMASK(13, 12)
-#define MTK_FOE_IB2_WHNAT_DEVIDX	BIT(16)
-#define MTK_FOE_IB2_WHNAT_NAT		BIT(17)
+#define MTK_FOE_IB2_WDMA_QID2		GENMASK(13, 12)
+#define MTK_FOE_IB2_WDMA_DEVIDX		BIT(16)
+#define MTK_FOE_IB2_WDMA_WINFO		BIT(17)
 
 #define MTK_FOE_IB2_PORT_MG		GENMASK(17, 12)
 
@@ -58,9 +58,9 @@ enum {
 
 #define MTK_FOE_IB2_DSCP		GENMASK(31, 24)
 
-#define MTK_FOE_VLAN2_WHNAT_BSS		GEMMASK(5, 0)
-#define MTK_FOE_VLAN2_WHNAT_WCID	GENMASK(13, 6)
-#define MTK_FOE_VLAN2_WHNAT_RING	GENMASK(15, 14)
+#define MTK_FOE_VLAN2_WINFO_BSS		GENMASK(5, 0)
+#define MTK_FOE_VLAN2_WINFO_WCID	GENMASK(13, 6)
+#define MTK_FOE_VLAN2_WINFO_RING	GENMASK(15, 14)
 
 enum {
 	MTK_FOE_STATE_INVALID,
@@ -281,6 +281,8 @@ int mtk_foe_entry_set_ipv6_tuple(struct
 int mtk_foe_entry_set_dsa(struct mtk_foe_entry *entry, int port);
 int mtk_foe_entry_set_vlan(struct mtk_foe_entry *entry, int vid);
 int mtk_foe_entry_set_pppoe(struct mtk_foe_entry *entry, int sid);
+int mtk_foe_entry_set_wdma(struct mtk_foe_entry *entry, int wdma_idx, int txq,
+			   int bss, int wcid);
 int mtk_foe_entry_commit(struct mtk_ppe *ppe, struct mtk_foe_entry *entry,
 			 u16 timestamp);
 int mtk_ppe_debugfs_init(struct mtk_ppe *ppe);
--- a/drivers/net/ethernet/mediatek/mtk_ppe_offload.c
+++ b/drivers/net/ethernet/mediatek/mtk_ppe_offload.c
@@ -11,6 +11,7 @@
 #include <net/pkt_cls.h>
 #include <net/dsa.h>
 #include "mtk_eth_soc.h"
+#include "mtk_wed.h"
 
 struct mtk_flow_data {
 	struct ethhdr eth;
@@ -40,6 +41,7 @@ struct mtk_flow_entry {
 	struct rhash_head node;
 	unsigned long cookie;
 	u16 hash;
+	s8 wed_index;
 };
 
 static const struct rhashtable_params mtk_flow_ht_params = {
@@ -130,7 +132,7 @@ mtk_flow_mangle_ipv4(const struct flow_a
 static int
 mtk_flow_set_output_device(struct mtk_eth *eth, struct mtk_foe_entry *foe,
 			   struct flow_offload_hw_action *offload_act,
-			   struct net_device *dev)
+			   struct net_device *dev, int *wed_index)
 {
 	int pse_port;
 
@@ -141,6 +143,14 @@ mtk_flow_set_output_device(struct mtk_et
 
 		mtk_foe_entry_set_dsa(foe, offload_act->act.dsa.port);
 		break;
+	case FLOW_OFFLOAD_HW_ACTION_WDMA:
+		mtk_foe_entry_set_wdma(foe, offload_act->act.wdma.wdma_idx,
+				       offload_act->act.wdma.queue,
+				       offload_act->act.wdma.bss,
+				       offload_act->act.wdma.wcid);
+		*wed_index = offload_act->act.wdma.wdma_idx;
+		mtk_foe_entry_set_pse_port(foe, 3);
+		return 0;
 	default:
 		break;
 	}
@@ -167,6 +177,7 @@ mtk_flow_offload_replace(struct mtk_eth
 	struct net_device *odev = NULL;
 	struct mtk_flow_entry *entry;
 	int offload_type = 0;
+	int wed_index = -1;
 	u16 addr_type = 0;
 	u32 timestamp;
 	u8 l4proto = 0;
@@ -314,10 +325,13 @@ mtk_flow_offload_replace(struct mtk_eth
 	if (data.pppoe.num == 1)
 		mtk_foe_entry_set_pppoe(&foe, data.pppoe.sid);
 
-	err = mtk_flow_set_output_device(eth, &foe, f->act, odev);
+	err = mtk_flow_set_output_device(eth, &foe, f->act, odev, &wed_index);
 	if (err)
 		return err;
 
+	if (wed_index >= 0 && (err = mtk_wed_flow_add(wed_index)) < 0)
+		return err;
+
 	entry = kzalloc(sizeof(*entry), GFP_KERNEL);
 	if (!entry)
 		return -ENOMEM;
@@ -331,6 +345,7 @@ mtk_flow_offload_replace(struct mtk_eth
 	}
 
 	entry->hash = hash;
+	entry->wed_index = wed_index;
 	err = rhashtable_insert_fast(&eth->flow_table, &entry->node,
 				     mtk_flow_ht_params);
 	if (err < 0)
@@ -341,6 +356,9 @@ clear_flow:
 	mtk_foe_entry_clear(&eth->ppe, hash);
 free:
 	kfree(entry);
+	if (wed_index >= 0)
+	    mtk_wed_flow_remove(wed_index);
+
 	return err;
 }
 
@@ -357,6 +375,8 @@ mtk_flow_offload_destroy(struct mtk_eth
 	mtk_foe_entry_clear(&eth->ppe, entry->hash);
 	rhashtable_remove_fast(&eth->flow_table, &entry->node,
 			       mtk_flow_ht_params);
+	if (entry->wed_index >= 0)
+		mtk_wed_flow_remove(entry->wed_index);
 	kfree(entry);
 
 	return 0;
--- a/include/linux/netdevice.h
+++ b/include/linux/netdevice.h
@@ -834,6 +834,7 @@ enum net_device_path_type {
 	DEV_PATH_BRIDGE,
 	DEV_PATH_PPPOE,
 	DEV_PATH_DSA,
+	DEV_PATH_WDMA,
 };
 
 struct net_device_path {
@@ -856,6 +857,7 @@ struct net_device_path {
 			__be16		vlan_proto;
 		} bridge;
 		struct flow_offload_action_dsa dsa;
+		struct flow_offload_action_wdma wdma;
 	};
 };
 
--- a/include/net/flow_offload.h
+++ b/include/net/flow_offload.h
@@ -555,15 +555,24 @@ struct flow_offload_action_dsa {
 	u16 proto;
 };
 
+struct flow_offload_action_wdma {
+	u8 wdma_idx;
+	u8 queue;
+	u8 bss;
+	u8 wcid;
+};
+
 enum flow_offload_hw_action_type {
 	FLOW_OFFLOAD_HW_ACTION_UNSPEC = 0,
 	FLOW_OFFLOAD_HW_ACTION_DSA,
+	FLOW_OFFLOAD_HW_ACTION_WDMA,
 };
 
 struct flow_offload_hw_action {
 	enum flow_offload_hw_action_type type;
 	union {
 		struct flow_offload_action_dsa dsa;
+		struct flow_offload_action_wdma wdma;
 	} act;
 };
 
--- a/net/core/dev.c
+++ b/net/core/dev.c
@@ -883,6 +883,10 @@ int dev_fill_forward_path(const struct n
 		if (WARN_ON_ONCE(last_dev == ctx.dev))
 			return -1;
 	}
+
+	if (!ctx.dev)
+		return ret;
+
 	path = dev_fwd_path(stack);
 	if (!path)
 		return -1;
--- a/net/netfilter/nf_flow_table_core.c
+++ b/net/netfilter/nf_flow_table_core.c
@@ -134,6 +134,7 @@ static int flow_offload_fill_route(struc
 
 	switch (route->tuple[dir].out.offload_act.type) {
 	case FLOW_OFFLOAD_HW_ACTION_DSA:
+	case FLOW_OFFLOAD_HW_ACTION_WDMA:
 		memcpy(&flow_tuple->out.offload_act,
 		       &route->tuple[dir].out.offload_act,
 		       sizeof(struct flow_offload_hw_action));
--- a/net/netfilter/nft_flow_offload.c
+++ b/net/netfilter/nft_flow_offload.c
@@ -68,6 +68,7 @@ struct nft_forward_info {
 	const struct net_device *outdev;
 	const struct net_device *hw_outdev;
 	const struct flow_offload_action_dsa *act_dsa;
+	const struct flow_offload_action_wdma *act_wdma;
 	struct id {
 		__u16	id;
 		__be16	proto;
@@ -150,6 +151,9 @@ static void nft_dev_path_info(const stru
 			}
 			info->xmit_type = FLOW_OFFLOAD_XMIT_DIRECT;
 			break;
+		case DEV_PATH_WDMA:
+			info->act_wdma = &path->wdma;
+			break;
 		default:
 			info->indev = NULL;
 			break;
@@ -186,13 +190,17 @@ static void nft_dev_fill_hw_offload_act(
 					enum ip_conntrack_dir dir,
 					struct nft_forward_info *info)
 {
-	if (info->act_dsa) {
-		struct flow_offload_hw_action *offload_act;
+	struct flow_offload_hw_action *offload_act;
 
-		offload_act = &route->tuple[dir].out.offload_act;
+	offload_act = &route->tuple[dir].out.offload_act;
+	if (info->act_dsa) {
 		offload_act->type = FLOW_OFFLOAD_HW_ACTION_DSA;
 		memcpy(&offload_act->act.dsa, info->act_dsa,
 		       sizeof(struct flow_offload_action_dsa));
+	} else if (info->act_wdma) {
+		offload_act->type = FLOW_OFFLOAD_HW_ACTION_WDMA;
+		memcpy(&offload_act->act.wdma, info->act_wdma,
+		       sizeof(struct flow_offload_action_wdma));
 	}
 }
 
